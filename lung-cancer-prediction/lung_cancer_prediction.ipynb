{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d6fffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1674d262",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data\n",
    "data = pd.read_csv('lung_cancer_examples.csv')\n",
    "print('Dataset :',data.shape)\n",
    "data.info()\n",
    "data[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dafd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of diagnosis\n",
    "data.Result.value_counts()[0:30].plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8725c6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "sns.pairplot(data,hue=\"Result\",size=3);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad7bb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data.drop(columns=['Name','Surname'],axis=1)\n",
    "data1 = data1.dropna(how='any')\n",
    "print(data1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9a7c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data1.shape)\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2e5a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data for training and testing\n",
    "#To select a set of training data that will be input in the Machine Learning algorithm, to ensure that the classification algorithm training can be generalized well to new data.\n",
    "#For this study using a sample size of 10%, assumed it ideal ratio between training and testing.\n",
    "from sklearn.model_selection import train_test_split\n",
    "Y = data1['Result']\n",
    "X = data1.drop(columns=['Result'])\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc17016",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X train shape: ', X_train.shape)\n",
    "print('Y train shape: ', Y_train.shape)\n",
    "print('X test shape: ', X_test.shape)\n",
    "print('Y test shape: ', Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcd74f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Defining the model\n",
    "logreg = LogisticRegression(C=10)\n",
    "\n",
    "#Training the model\n",
    "logreg.fit(X_train, Y_train)\n",
    "\n",
    "#Predicting the target values\n",
    "Y_predict1 = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e43679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "logreg_cm = confusion_matrix(Y_test, Y_predict1)\n",
    "f, ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(logreg_cm, annot=True, linewidth=0.7, linecolor='cyan', fmt='g', ax=ax, cmap=\"YlGnBu\")\n",
    "plt.title('Logistic Regression Classification Confusion Matrix')\n",
    "plt.xlabel('Y predict')\n",
    "plt.ylabel('Y test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc6a962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score\n",
    "score_logreg = logreg.score(X_test, Y_test)\n",
    "print(score_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5353183",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM (Support Vector Machine) classification\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#Defining the SVM model\n",
    "svmcla = OneVsRestClassifier(BaggingClassifier(SVC(C=10,kernel='rbf',random_state=9, probability=True), n_jobs=-1))\n",
    "\n",
    "#Training the model\n",
    "svmcla.fit(X_train, Y_train)\n",
    "\n",
    "#Pedicting the target values\n",
    "Y_predict2 = svmcla.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ab505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The confusion matrix\n",
    "svmcla_cm = confusion_matrix(Y_test, Y_predict2)\n",
    "f, ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(svmcla_cm, annot=True, linewidth=0.7, linecolor='cyan', fmt='g', ax=ax, cmap=\"YlGnBu\")\n",
    "plt.title('SVM Classification Confusion Matrix')\n",
    "plt.xlabel('Y predict')\n",
    "plt.ylabel('Y test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc16da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score\n",
    "score_svmcla = svmcla.score(X_test, Y_test)\n",
    "print(score_svmcla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fde20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive bayes classification\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Defining the model\n",
    "nbcla = GaussianNB()\n",
    "\n",
    "#Training the model\n",
    "nbcla.fit(X_train, Y_train)\n",
    "\n",
    "#Predicting the target values\n",
    "Y_predict3 = nbcla.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e95065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The confusion matrix\n",
    "nbcla_cm = confusion_matrix(Y_test, Y_predict3)\n",
    "f, ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(nbcla_cm, annot=True, linewidth=0.7, linecolor='cyan', fmt='g', ax=ax, cmap=\"YlGnBu\")\n",
    "plt.title('Naive Bayes Classification Confusion Matrix')\n",
    "plt.xlabel('Y predict')\n",
    "plt.ylabel('Y test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a85e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score\n",
    "score_nbcla = nbcla.score(X_test, Y_test)\n",
    "print(score_nbcla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688fd6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision tree classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Defining the model\n",
    "dtcla = DecisionTreeClassifier(random_state=9)\n",
    "\n",
    "#Training the model\n",
    "dtcla.fit(X_train, Y_train)\n",
    "\n",
    "#Predicting the target values\n",
    "Y_predict4 = dtcla.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262dc3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The confusion matrix\n",
    "dtcla_cm = confusion_matrix(Y_test, Y_predict4)\n",
    "f, ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(dtcla_cm, annot=True, linewidth=0.7, linecolor='cyan', fmt='g', ax=ax, cmap=\"YlGnBu\")\n",
    "plt.title('Decision Tree Classification Confusion Matrix')\n",
    "plt.xlabel('Y predict')\n",
    "plt.ylabel('Y test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc84ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score\n",
    "score_dtcla = dtcla.score(X_test, Y_test)\n",
    "print(score_dtcla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3964b395",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random forest classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Defining the model\n",
    "rfcla = RandomForestClassifier(n_estimators=100,random_state=9,n_jobs=-1)\n",
    "\n",
    "#Training the model\n",
    "rfcla.fit(X_train, Y_train)\n",
    "\n",
    "#Predicting the target values\n",
    "Y_predict5 = rfcla.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79a5712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The confusion matrix\n",
    "rfcla_cm = confusion_matrix(Y_test, Y_predict5)\n",
    "f, ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(rfcla_cm, annot=True, linewidth=0.7, linecolor='cyan', fmt='g', ax=ax, cmap=\"YlGnBu\")\n",
    "plt.title('Random Forest Classification Confusion Matrix')\n",
    "plt.xlabel('Y predict')\n",
    "plt.ylabel('Y test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff421e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score\n",
    "score_rfcla = rfcla.score(X_test, Y_test)\n",
    "print(score_rfcla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62889a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-Nearest Neighbor classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Defining the model\n",
    "knncla = KNeighborsClassifier(n_neighbors=5,n_jobs=-1)\n",
    "\n",
    "#Training the model\n",
    "knncla.fit(X_train, Y_train)\n",
    "\n",
    "#Predicting the target values\n",
    "Y_predict6 = knncla.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cee641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The confusion matrix\n",
    "knncla_cm = confusion_matrix(Y_test, Y_predict6)\n",
    "f, ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(knncla_cm, annot=True, linewidth=0.7, linecolor='cyan', fmt='g', ax=ax, cmap=\"YlGnBu\")\n",
    "plt.title('KNN Classification Confusion Matrix')\n",
    "plt.xlabel('Y predict')\n",
    "plt.ylabel('Y test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d95b9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score\n",
    "score_knncla= knncla.score(X_test, Y_test)\n",
    "print(score_knncla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d012833",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test score\n",
    "Testscores = pd.Series([score_logreg, score_svmcla, score_nbcla, score_dtcla, score_rfcla, score_knncla], \n",
    "                        index=['Logistic Regression Score', 'Support Vector Machine Score', 'Naive Bayes Score', 'Decision Tree Score', 'Random Forest Score', 'K-Nearest Neighbour Score']) \n",
    "print(Testscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad4cd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The confusion matrix\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "ax1 = fig.add_subplot(3, 3, 1) \n",
    "ax1.set_title('Logistic Regression Classification') \n",
    "ax2 = fig.add_subplot(3, 3, 2) \n",
    "ax2.set_title('SVM Classification')\n",
    "ax3 = fig.add_subplot(3, 3, 3)\n",
    "ax3.set_title('Naive Bayes Classification')\n",
    "ax4 = fig.add_subplot(3, 3, 4)\n",
    "ax4.set_title('Decision Tree Classification')\n",
    "ax5 = fig.add_subplot(3, 3, 5)\n",
    "ax5.set_title('Random Forest Classification')\n",
    "ax6 = fig.add_subplot(3, 3, 6)\n",
    "ax6.set_title('KNN Classification')\n",
    "sns.heatmap(data=logreg_cm, annot=True, linewidth=0.7, linecolor='cyan',cmap=\"YlGnBu\" ,fmt='g', ax=ax1)\n",
    "sns.heatmap(data=svmcla_cm, annot=True, linewidth=0.7, linecolor='cyan',cmap=\"YlGnBu\" ,fmt='g', ax=ax2)  \n",
    "sns.heatmap(data=nbcla_cm, annot=True, linewidth=0.7, linecolor='cyan',cmap=\"YlGnBu\" ,fmt='g', ax=ax3)\n",
    "sns.heatmap(data=dtcla_cm, annot=True, linewidth=0.7, linecolor='cyan',cmap=\"YlGnBu\" ,fmt='g', ax=ax4)\n",
    "sns.heatmap(data=rfcla_cm, annot=True, linewidth=0.7, linecolor='cyan',cmap=\"YlGnBu\" ,fmt='g', ax=ax5)\n",
    "sns.heatmap(data=knncla_cm, annot=True, linewidth=0.7, linecolor='cyan',cmap=\"YlGnBu\" ,fmt='g', ax=ax6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06beae79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC curve\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Logistic Regression Classification\n",
    "Y_predict1_proba = logreg.predict_proba(X_test)\n",
    "Y_predict1_proba = Y_predict1_proba[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, Y_predict1_proba)\n",
    "plt.subplot(331)\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.plot(fpr,tpr, label='ANN')\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('ROC Curve Logistic Regression')\n",
    "plt.grid(True)\n",
    "\n",
    "# SVM Classification\n",
    "Y_predict2_proba = svmcla.predict_proba(X_test)\n",
    "Y_predict2_proba = Y_predict2_proba[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, Y_predict2_proba)\n",
    "plt.subplot(332)\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.plot(fpr,tpr, label='ANN')\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('ROC Curve SVM')\n",
    "plt.grid(True)\n",
    "\n",
    "# Naive Bayes Classification\n",
    "Y_predict3_proba = nbcla.predict_proba(X_test)\n",
    "Y_predict3_proba = Y_predict3_proba[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, Y_predict3_proba)\n",
    "plt.subplot(333)\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.plot(fpr,tpr, label='ANN')\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('ROC Curve Naive Bayes')\n",
    "plt.grid(True)\n",
    "\n",
    "# Decision Tree Classification\n",
    "Y_predict4_proba = dtcla.predict_proba(X_test)\n",
    "Y_predict4_proba = Y_predict4_proba[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, Y_predict4_proba)\n",
    "plt.subplot(334)\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.plot(fpr,tpr, label='ANN')\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('ROC Curve Decision Tree')\n",
    "plt.grid(True)\n",
    "\n",
    "# Random Forest Classification\n",
    "Y_predict5_proba = rfcla.predict_proba(X_test)\n",
    "Y_predict5_proba = Y_predict5_proba[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, Y_predict5_proba)\n",
    "plt.subplot(335)\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.plot(fpr,tpr, label='ANN')\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('ROC Curve Random Forest')\n",
    "plt.grid(True)\n",
    "\n",
    "# KNN Classification\n",
    "Y_predict6_proba = knncla.predict_proba(X_test)\n",
    "Y_predict6_proba = Y_predict6_proba[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, Y_predict6_proba)\n",
    "plt.subplot(336)\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.plot(fpr,tpr, label='ANN')\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('ROC Curve KNN')\n",
    "plt.grid(True)\n",
    "plt.subplots_adjust(top=2, bottom=0.08, left=0.10, right=1.4, hspace=0.45, wspace=0.45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ab5370",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1 = data1['Result']\n",
    "X1 = data1.drop(columns=['Age'])\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "lsvc = LinearSVC(C=0.06, penalty=\"l1\", dual=False,random_state=10).fit(X1, Y1)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_new = model.transform(X1)\n",
    "cc = list(X1.columns[model.get_support(indices=True)])\n",
    "print(cc)\n",
    "print(len(cc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab83a009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principal component analysis\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA().fit(X1)\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Smokes AreaQ Alkhol Result')\n",
    "plt.ylabel('% Variance Explained')\n",
    "plt.title('PCA Analysis')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4eec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of total variance explained\n",
    "variance = pd.Series(list(np.cumsum(pca.explained_variance_ratio_)), \n",
    "                        index= list(range(1,5))) \n",
    "print(variance[10:90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d37e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = data1[cc] \n",
    "from sklearn.model_selection import train_test_split\n",
    "X1_train, X1_test, Y1_train, Y1_test = train_test_split(X1, Y1, test_size=0.1, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f31fdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression classification\n",
    "logreg.fit(X1_train, Y1_train)\n",
    "Y1_predict1 = logreg.predict(X1_test)\n",
    "logreg_cm = confusion_matrix(Y1_test, Y1_predict1)\n",
    "score1_logreg = logreg.score(X1_test, Y1_test)\n",
    "\n",
    "# SVM classification\n",
    "svmcla.fit(X1_train, Y1_train)\n",
    "Y1_predict2 = svmcla.predict(X1_test)\n",
    "svmcla_cm = confusion_matrix(Y1_test, Y1_predict2)\n",
    "score1_svmcla = svmcla.score(X1_test, Y1_test)\n",
    "\n",
    "# Random forest classification\n",
    "rfcla.fit(X1_train, Y1_train)\n",
    "Y1_predict5 = rfcla.predict(X1_test)\n",
    "rfcla_cm = confusion_matrix(Y1_test, Y1_predict5)\n",
    "score1_rfcla = rfcla.score(X1_test, Y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1b835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Testscores1 = pd.Series([score1_logreg, score1_svmcla, score1_rfcla], index=['Logistic Regression Score', \n",
    "                        'Support Vector Machine Score', 'Random Forest Score']) \n",
    "print(Testscores1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f149778",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,15))\n",
    "ax1 = fig.add_subplot(3, 3, 1) \n",
    "ax1.set_title('Logistic Regression Classification') \n",
    "ax2 = fig.add_subplot(3, 3, 2) \n",
    "ax2.set_title('SVM Classification')\n",
    "ax5 = fig.add_subplot(3, 3,3)\n",
    "ax5.set_title('Random Forest Classification')\n",
    "\n",
    "sns.heatmap(data=logreg_cm, annot=True, linewidth=0.7, linecolor='cyan',cmap=\"YlGnBu\" ,fmt='g', ax=ax1)\n",
    "sns.heatmap(data=svmcla_cm, annot=True, linewidth=0.7, linecolor='cyan',cmap=\"YlGnBu\" ,fmt='g', ax=ax2)  \n",
    "sns.heatmap(data=rfcla_cm, annot=True, linewidth=0.7, linecolor='cyan',cmap=\"YlGnBu\" ,fmt='g', ax=ax5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bf9acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1 = data1['Result']\n",
    "X1 = data1.drop(columns=['AreaQ'])\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "lsvc = LinearSVC(C=0.06, penalty=\"l1\", dual=False,random_state=10).fit(X1, Y1)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_new = model.transform(X1)\n",
    "cc = list(X1.columns[model.get_support(indices=True)])\n",
    "print(cc)\n",
    "print(len(cc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4125546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principal component analysis\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA().fit(X1)\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Age Smokes Alkhol Result')\n",
    "plt.ylabel('% Variance Explained')\n",
    "plt.title('PCA Analysis')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2195376e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of total variance explained\n",
    "variance = pd.Series(list(np.cumsum(pca.explained_variance_ratio_)), \n",
    "                        index= list(range(1,5))) \n",
    "print(variance[10:90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea63309e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = data1[cc] \n",
    "from sklearn.model_selection import train_test_split\n",
    "X1_train, X1_test, Y1_train, Y1_test = train_test_split(X1, Y1, test_size=0.1, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583ece23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression classification\n",
    "logreg.fit(X1_train, Y1_train)\n",
    "Y1_predict1 = logreg.predict(X1_test)\n",
    "logreg_cm = confusion_matrix(Y1_test, Y1_predict1)\n",
    "score1_logreg = logreg.score(X1_test, Y1_test)\n",
    "\n",
    "# SVM classification\n",
    "svmcla.fit(X1_train, Y1_train)\n",
    "Y1_predict2 = svmcla.predict(X1_test)\n",
    "svmcla_cm = confusion_matrix(Y1_test, Y1_predict2)\n",
    "score1_svmcla = svmcla.score(X1_test, Y1_test)\n",
    "\n",
    "# Random forest classification\n",
    "rfcla.fit(X1_train, Y1_train)\n",
    "Y1_predict5 = rfcla.predict(X1_test)\n",
    "rfcla_cm = confusion_matrix(Y1_test, Y1_predict5)\n",
    "score1_rfcla = rfcla.score(X1_test, Y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5702b3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Testscores1 = pd.Series([score1_logreg, score1_svmcla, score1_rfcla], index=['Logistic Regression Score', \n",
    "                        'Support Vector Machine Score', 'Random Forest Score']) \n",
    "print(Testscores1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f08f74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,15))\n",
    "ax1 = fig.add_subplot(3, 3, 1) \n",
    "ax1.set_title('Logistic Regression Classification') \n",
    "ax2 = fig.add_subplot(3, 3, 2) \n",
    "ax2.set_title('SVM Classification')\n",
    "ax5 = fig.add_subplot(3, 3,3)\n",
    "ax5.set_title('Random Forest Classification')\n",
    "sns.heatmap(data=logreg_cm, annot=True, linewidth=0.7, linecolor='cyan',cmap=\"YlGnBu\" ,fmt='g', ax=ax1)\n",
    "sns.heatmap(data=svmcla_cm, annot=True, linewidth=0.7, linecolor='cyan',cmap=\"YlGnBu\" ,fmt='g', ax=ax2)  \n",
    "sns.heatmap(data=rfcla_cm, annot=True, linewidth=0.7, linecolor='cyan',cmap=\"YlGnBu\" ,fmt='g', ax=ax5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f33678",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1 = data1['Result']\n",
    "X1 = data1.drop(columns=['Alkhol'])\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "lsvc = LinearSVC(C=0.06, penalty=\"l1\", dual=False,random_state=10).fit(X1, Y1)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_new = model.transform(X1)\n",
    "cc = list(X1.columns[model.get_support(indices=True)])\n",
    "print(cc)\n",
    "print(len(cc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324cc95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principal component analysis\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA().fit(X1)\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Age Smokes AreaQ Result')\n",
    "plt.ylabel('% Variance Explained')\n",
    "plt.title('PCA Analysis')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1df275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of total variance explained\n",
    "variance = pd.Series(list(np.cumsum(pca.explained_variance_ratio_)), \n",
    "                        index= list(range(1,5))) \n",
    "print(variance[10:90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fd8d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = data1[cc] \n",
    "from sklearn.model_selection import train_test_split\n",
    "X1_train, X1_test, Y1_train, Y1_test = train_test_split(X1, Y1, test_size=0.1, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa27867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression classification\n",
    "logreg.fit(X1_train, Y1_train)\n",
    "Y1_predict1 = logreg.predict(X1_test)\n",
    "logreg_cm = confusion_matrix(Y1_test, Y1_predict1)\n",
    "score1_logreg = logreg.score(X1_test, Y1_test)\n",
    "\n",
    "# SVM classification\n",
    "svmcla.fit(X1_train, Y1_train)\n",
    "Y1_predict2 = svmcla.predict(X1_test)\n",
    "svmcla_cm = confusion_matrix(Y1_test, Y1_predict2)\n",
    "score1_svmcla = svmcla.score(X1_test, Y1_test)\n",
    "\n",
    "# Random forest classification\n",
    "rfcla.fit(X1_train, Y1_train)\n",
    "Y1_predict5 = rfcla.predict(X1_test)\n",
    "rfcla_cm = confusion_matrix(Y1_test, Y1_predict5)\n",
    "score1_rfcla = rfcla.score(X1_test, Y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45927c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "Testscores1 = pd.Series([score1_logreg, score1_svmcla, score1_rfcla], index=['Logistic Regression Score', \n",
    "                        'Support Vector Machine Score', 'Random Forest Score']) \n",
    "print(Testscores1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036724c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,15))\n",
    "ax1 = fig.add_subplot(3, 3, 1) \n",
    "ax1.set_title('Logistic Regression Classification') \n",
    "ax2 = fig.add_subplot(3, 3, 2) \n",
    "ax2.set_title('SVM Classification')\n",
    "ax5 = fig.add_subplot(3, 3,3)\n",
    "ax5.set_title('Random Forest Classification')\n",
    "sns.heatmap(data=logreg_cm, annot=True, linewidth=0.7, linecolor='cyan',cmap=\"YlGnBu\" ,fmt='g', ax=ax1)\n",
    "sns.heatmap(data=svmcla_cm, annot=True, linewidth=0.7, linecolor='cyan',cmap=\"YlGnBu\" ,fmt='g', ax=ax2)  \n",
    "sns.heatmap(data=rfcla_cm, annot=True, linewidth=0.7, linecolor='cyan',cmap=\"YlGnBu\" ,fmt='g', ax=ax5)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
